# ME369P-U19
ME 369P Project
The goal of our final project was to develop create a robot simultaion that would be able to have its movements controlled using gesture recognition. Below we will explain the different aspects of our code and how each program works.

Training Gesture Recognition Inputs(Final_Project_Hand_Detection.py)
1. Open Final_Project_Hand_Detection.py
2. Make sure that you have mediapipe, cv2, numpy, and pickle installed
3. Make sure you have the ROS Inputs.pkl downloaded (This is the file of trained gestures for movement)
4. Once you run the program you can use the gestures shown in file to output the values right, left, speed 1, speed 2, speed 3, and stop. These will be later used to control the robot in the simulation.
